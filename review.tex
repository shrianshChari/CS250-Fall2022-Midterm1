\documentclass{article}

\usepackage{amssymb}

\title{CS 250 Midterm 1 - Fall 2022}
\author{schari}
\date{September 2022}

\begin{document}
\maketitle

\section{Sections of textbook to review}
\begin{itemize}
	\item Chapter 3
	\item Chapter 4
	\item Chapter 2.17
	\item Chapter 5.1-5.10
\end{itemize}

\section{What is Computer Architecture?}

\section{Information Representation}
\begin{itemize}
	\item Computers use a representation defined by a pair of symbols to represent all kinds of information
		\begin{itemize}
			\item This is known as a bit, where a bit is defined as either a 0 or a 1
			\item A bit string is an ordered sequence of bits
			\item A byte is an 8-bit bit string
			\item Ex: 01101001 is a byte and a bit string
		\end{itemize}
	\item The reason computers use a 2-symbol representation is because it is easy to do so by controlling voltage; on is a 1 and off is a 0
	\item How do you represent a bit string electrically?
		\begin{itemize}
			\item To represent a $k$-bit string electrically, you'll want $k$ wires to each hold one bit of the string
			\item A bunch of $k$ wires carrying $k$ bits for a $k$-bit string is a $k$-bit \textbf{bus}.
			\item On a diagram, you typically see a bus represented as a single line.
			\item A $k$-bit string can represent $2^k$ unique sequences
		\end{itemize}
	\item Hexadecimal Notation
		\begin{itemize}
			\item To shorten the binary data that computers read, we usually use hexadecimal notation to view binary data
			\item 4 bits map to one hexadecimal digit
				\begin{table}
					\caption{Table between hexadecimal, binary, and decimal values}
					\begin{center}
						\begin{tabular}[h]{l l l}
							Hexadecimal & Binary & Decimal \\
							\hline
							0 & 0000 & 0 \\
							1 & 0001 & 1 \\
							2 & 0010 & 2 \\
							3 & 0011 & 3 \\
							4 & 0100 & 4 \\
							5 & 0101 & 5 \\
							6 & 0110 & 6 \\
							7 & 0111 & 7 \\
							8 & 1000 & 8 \\
							9 & 1001 & 9 \\
							A & 1000 & 10 \\
							B & 1011 & 11 \\
							C & 1100 & 12 \\
							D & 1101 & 13 \\
							E & 1100 & 14 \\
							F & 1111 & 15 \\
							\hline
						\end{tabular}
					\end{center}
				\end{table}
		\end{itemize}
	\item Prefixes for $2^k$
		\begin{itemize}
			\item Kibi is $2^{10} \approx 10^3$ (which is kilo)
			\item Mebi is $2^{20} \approx 10^6$ (which is mega)
			\item Gibi is $2^{30} \approx 10^9$ (which is giga)
			\item Tebi is $2^{40} \approx 10^{12}$ (which is tera)
			\item Note: you drop the last two letters of the $10^k$ prefix and add bi (for binary) to approximate the $2^k$ prefix
			\item $2^{10} = 1024$ and $10^3 = 1000$
		\end{itemize}
\end{itemize}

\section{Computer Memory}
\begin{itemize}
	\item \textbf{Memory} is computer hardware that functions can write data to and read data from
	\item Memory contains locations where data is stored, as well as unique addresses that point to those locations
		\begin{itemize}
			\item How do we define $2^k$ unique ``points" in physical memory with $k$ bits?
			\item We delegate $2^{{k}/{2}}$ wires of the bit string as ``horizontal" wires and the other $2^{k/2}$ wires of the bit string as ``vertical" wires
			\item This creates a grid with $2^k$ individual locations defined by $k$ bits
		\end{itemize}
	\item With this, we can define a pointer-mapping circuit that takes a $k$-bit pointer that maps to $2^k$ locations in memory
	\item What actually goes at each of these ``locations"?
		\begin{itemize}
			\item You would use a piece of circuitry called a \textbf{register}.
			\item The register is made up of 4 parts: $k$ 1-bit latches (1 latch for each bit), an enable line, an input bus, and an output bus
			\item The output bus returns the contents of the latches (which each store one bit in the bit string)
			\item The enable line tells the latch when to accept new values for each bit through the input bus (the latches won't change in value until we tell it to change)
		\end{itemize}
	\item Pointing
		\begin{itemize}
			\item To actually receive data from memory, we use a circuit called a \textbf{decoder}
			\item The decoder has $k$ wires as an input and $2^k$ wires as an output
			\item Based on the input wires, the decoder will have one of the output wires carrying voltage, while the rest of them have no voltage
			\item One of the applications of a decoder is to use the decoder as a pointer-mapping circuit that points a $k$-bit address to one of $2^k$ locations in memory
		\end{itemize}
	\item The multiplexer (mux)
		\begin{itemize}
			\item The multiplexer is a circuit that takes in an address and returns the contents of the location in memory that address points to
			\item It is used to read data from memory
			\item It has 2 inputs: an $n$-bit bus that represents the address of the register you want the data of, and $2^n$ $k$-bit buses that represent the wires connecting from the memory to the mux
			\item The mux is given the address as input, then the mux retrieves the data from the corresponding bus
			\item The mux then outputs the data through its $k$-bit bus
		\end{itemize}
	\item The demultiplexer (demux)
		\begin{itemize}
			\item The demultiplexer is a circuit that takes in an address and some data and writes that data to the location in memory that address points to
			\item It has 2 inputs: an $n$-bit bus that represents the address of the register you want to write to, and a $k$-bit bus that represents the new data you want to store the value of
			\item The demux points to one of the corresponding $2^n$ $k$-bit output buses and outputs the $k$-bit string to write the string to the corresponding location in memory
			\item Essentially the inverse of the mux function; mux function reads information, while the demux function writes information
		\end{itemize}
	\item When a bit string is transported from memory to the processor, it's called a fetch.
\end{itemize}

\section{Processors}
\begin{itemize}
	\item The Harvard and Von Neumann architectures
		\begin{itemize}
			\item The major difference between the two architectures is that the Harvard architecture has separate memory areas for holding the instructions and the data, whereas the Von Neumann architecture contains it all in one memory
			\item Pros vs Cons of each:
				\begin{itemize}
					\item Harvard
						\begin{itemize}
							\item Pros: Simultaneous access of instructions and data, can optimize the memory design specifically for instructions and data
							\item Cons: Two potential memory bottlenecks; may run out of memory for instructions or data
						\end{itemize}
					\item Von Neumann
						\begin{itemize}
							\item Pros: Requires less memory; both of them occupy the same memory
							\item Cons: Less secure because a given address could either point to an address or a piece of data
						\end{itemize}
				\end{itemize}
			\item Nowadays, most processors use the Von Neumann architecture
		\end{itemize}
	\item What are processors?
		\begin{itemize}
			\item Many people use processor the same way as they use CPU, but they are not the same thing; processors are just a chip that can perform a multistep computation
		\end{itemize}
	\item A general-purpose processor
		\begin{itemize}
			\item Why would you want a processor that can do a lot of things vs one that does a few things very efficiently?
			\item More cost-effective to manufacture a lot of a few processors than lots of different processors
			\item The blueprint of a general-purpose processor contains a few things: a store of memory that stores data, a circuit that conducts computation (called an \textbf{ALU}, or Arithmetic and Logic Unit), and MUXes and DeMUXes to read data to the ALU and write the results of the computation back to memory
			\item The ALU contains MUXes that point the operands passed in as the input data to the corresponding engines to conduct the computation (ex, an arithmetic engine, a graphics engine, etc)
		\end{itemize}
	\item Representing machine code execution with a general-purpose processor
		\begin{itemize}
			\item To execute a computation, you need an address pointing to the instruction that you wish to execute
			\item This means that you have to store computation in memory
			\item Some may choose to store their instructions separately from the data (which is Harvard architecture)
		\end{itemize}
	\item Executing instructions
		\begin{itemize}
			\item A simplistic model for how computers execute machine instructions is the fetch-execute model
			\item Essentially, the computer fetches the next instruction, then executes it
			\item What happens when there is nothing else to execute?
			\item The software must figure out what the processor needs to execute next
			\item In a dedicated processor, the main application will execute endlessly
			\item In a general-purpose processor, the operating system will have an idle loop for the processor to run while waiting for the next process to be run
		\end{itemize}
	\item Clock Rate and Processor Speed
		\begin{itemize}
			\item Many circuits have a clock that paces the circuit's execution (how often should the processor execute an instruction?)
			\item The registers and muxes/demuxes have a fixed delay between operations
			\item The different functions in an ALU can have differing amounts of delay
			\item Benchmarking a processor's execution
				\begin{itemize}
					\item Benchmarking a processor's performance when executing a program requires 3 values:
						\begin{itemize}
							\item $\displaystyle\frac{Instructions}{Program}$ depends on the algorithm being executed (Software)
							\item $\displaystyle\frac{Clock ~ cycles}{Instruction}$ depends on the compiler and circuit design (SW + Hardware)
							\item $\displaystyle\frac{Seconds}{Clock ~ cycle}$ depends the worst-case delay (HW)
							\item The final fraction is $\displaystyle\frac{Seconds}{Program}$
						\end{itemize}
				\end{itemize}
		\end{itemize}
\end{itemize}

\section{Machine Instructions}
\begin{itemize}
	\item What operations should a processor be able to do?
		\begin{itemize}
			\item What people want their processors to be able to do
			\item It is a design challenge
			\item People want their processors to do a lot
			\item What they want the processors to do can change over time
			\item The influence of different people can shift over time
			\item Other considerations: technology, cost, adoption
		\end{itemize}
	\item The set of operations a processor can do is the \textbf{instruction set architecture} (ISA)
	\item How do we go from HLLs to machine instructions?
		\begin{itemize}
			\item HLLs might have instructions that doesn't correspond with a machine instruction
			\item There might exist machine instructions that doesn't correspond to a HLL instruction
			\item What matters is that every HLL instruction can be executed with a combination of machine instructions
		\end{itemize}
	\item ISA considerations
		\begin{itemize}
			\item The ability for an ISA to execute every possible program, Turing completeness takes little of the ISA's capabilities
			\item What really matters
				\begin{itemize}
					\item Programmer convenience: the ability for a few lines of code to do a lot of computation
					\item The cost of a processor to execute so many instructions
					\item Considerations like heat and speed of the circuit
				\end{itemize}
		\end{itemize}
	\item An ISA exists to control the general-purpose processor circuit
	\item Therefore, you pair a bit string with an instruction and configure the circuit to execute the corresponding instruction when it gets its bit string
	\item What goes in a machine instruction?
		\begin{itemize}
			\item Composed of 3 parts: the opcode, the operands, and the result
			\item All of these individual parts are represented by bit strings
			\item Opcode
				\begin{itemize}
					\item Required since it tells the ALU what to do
					\item The encoding is up to the ISA designer, not portable between ISAs
				\end{itemize}
			\item Operands
				\begin{itemize}
					\item Inputs of the computation
					\item Number of operands defined by opcode
					\item Pointers to the location containing the data
					\item Sometimes contains extra information indicating the encoding of the data (e.g. 2's complement)
				\end{itemize}
			\item Results
				\begin{itemize}
					\item Number of results defined by opcode
					\item Pointer to location that will store the result of the computation
					\item Not uncommon for a zero-bit pointer to be supplied
				\end{itemize}
		\end{itemize}
	\item Instruction size; two ways to design a length of a machine instruction
		\begin{itemize}
			\item Variable length
				\begin{itemize}
					\item Pros: can create as many instructions as you want; just add bytes, can choose short encoding for common instructions for quick execution, Easier to market as a feature
					\item Cons: variable length means you have to expend extra computation time to get what the instruction actually is before you even compute it, compiler writers might worry about ISA compatibility, no one else really writes in machine code
				\end{itemize}
			\item Fixed length
				\begin{itemize}
					\item Pros: Easier to fetch instructions from memory, decryption of instructions is simpler, criteria for instruction inclusion is largely technical since you can't add new bytes in the future, compiler writers like fixed length because then compiling to machine code is easier
					\item Cons: instructions using only a few fields might not use all bits of fixed length string, cannot market "expanded ISA" because fixed length means you can't expand it
				\end{itemize}
			\item Both are measured in terms of bytes
		\end{itemize}
	\item Instruction length and its growth
		\begin{itemize}
			\item To represent each location of 4 GB of memory, you need a 32 bit pointer
			\item For 16 GB of memory, you'd need 34 bit pointer
			\item The number of bits you need to use to represent your memory increases as more memory becomes prevalent as a result of Moore's Law
			\item $\therefore$ general-purpose processors that use 32 bit pointers or less have become obsolete
			\item Variable length ISAs can adapt by adding an "address extension"
			\item Fixed length ISAs have more limited options
		\end{itemize}
	\item Constant pointer sizes?
		\begin{itemize}
			\item Idea is to have a small number of registers that the ALU can directly access instead of accessing from memory
			\item This means pointers can remain small while also increasing amount of memory
			\item You'd typically see two kinds of registers: general registers for bit strings and integers, and floating point registers for floating point values (IEEE 754)
		\end{itemize}
	\item Fixed length memory access
		\begin{itemize}
			\item There are two instructions for getting memory into the registers: LOAD and STORE
			\item You would LOAD the information from memory into the registers, tell the ALU to use the registers for the computation, then STORE the result in the memory
			\item Using these register banks makes a more complicated circuit than one without register banks
		\end{itemize}
	\item Examples of ISA used
		\begin{itemize}
			\item Historic: PDP-1, IBM 360, DEC VAX, x86
			\item SPARC (what \verb|lore| uses)
			\item x86-64 (aka amd64, x86\_64, x64, Intel 64)
			\item PowerPC
			\item ARM
		\end{itemize}
	\item Early ISAs
		\begin{itemize}
			\item Memory is expensive; locations store one byte
			\item Chips have limited pins, so limited I/O
			\item Wanted to keep instruction bit strings short
			\item 8-bit pointers, have specialized 0-bit registers
			\item Programmers would write programs in machine language, so they would want some sophisticated instructions (could also lead to feature creep)
			\item Wanted to have many different instructions
			\item They would give instructions encodings in increments of 8 bits
			\item More used instructions would be given shorter encodings
		\end{itemize}
	\item x86
		\begin{itemize}
			\item Became very successful early on thanks to inclusion in IBM PC
			\item Would receive several expansions to modernize it
			\item Various extensions patented by both Intel and AMD
			\item x86-64
			\begin{itemize}
				\item 64-bit extension of x86 architecture
				\item x86-64 is owned by AMD, but x86 owned by Intel, so both are linked to ISA
				\item Variable length from 1 to 15 bytes
				\item Circuit has large propagation delay and large power consumption that doesn't improve computation performance
				\item However, it's so widely used that it's still used nearly 50 years later
			\end{itemize}
		\end{itemize}
\end{itemize}

\section{Why Assembly?}
\end{document}
